<!DOCTYPE html>
<html class="js no-touch  progressive-image  no-reduced-motion progressive" lang="zh-hans">
  <head>
    <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link rel="icon" href="/img/favicon.ico">

    <meta name="keyword" content=""><meta property="og:title" content="Python爬虫之scrapy框架" />
<meta property="og:description" content="Python爬虫之scrapy框架 创建项目 scrapy startproject 项目名 创建爬虫 scrapy genspider 爬虫识别名称 &lsquo;要爬取的主机地址&rsquo; 运行爬虫 scrapy crawl 爬虫识别" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Bscrapy%E6%A1%86%E6%9E%B6-python%E7%88%AC%E8%99%AB%E4%B9%8Bscrapy%E6%A1%86%E6%9E%B6/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-26T21:51:43+00:00" />
<meta property="article:modified_time" content="2021-11-26T21:51:43+00:00" />
<title>Python爬虫之scrapy框架</title>

    <link rel="canonical" href="/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Bscrapy%E6%A1%86%E6%9E%B6-python%E7%88%AC%E8%99%AB%E4%B9%8Bscrapy%E6%A1%86%E6%9E%B6/">

    <link rel="stylesheet" href="/css/global.css">

    <link rel="stylesheet" href="/css/custom.css">

    <link rel="stylesheet" href="/css/search.css" />

    
    

    
    

</head>
  </head>
  <body class=" page-article   ">
    <header>
      <nav class="nav">
  <div class="nav-wrapper">
    <div class="nav-content-wrapper">
      <div class="nav-content">
        <a href="/ " class="nav-title">🧀</a>
        <div class="nav-menu">
          <div class="nav-item-wrapper">
            <a href="/posts " class="nav-item-content">目录</a>
          </div><div class="nav-item-wrapper">
            <a href="/about" class="nav-item-content">关于</a>
          </div><div class="nav-item-wrapper">
            <a href="/index.xml" class="nav-item-content" target="_blank">RSS</a>
          </div></div>
      </div>
    </div>
  </div>
</nav>

<script>
  function toggleSearchModal(){
    const template = `
    <div class="modal-body">
      <div id="autocomplete" onclick="event.stopPropagation();"></div>
    </div>
    `
    const modal = document.querySelector("#modal-wrapper")
    if(!modal){
      const div = document.createElement("div")
      document.body.setAttribute("style","overflow: hidden;")
      div.setAttribute("id", "modal-wrapper")
      div.setAttribute("onclick", "toggleSearchModal()")
      div.innerHTML = template
      const script = document.createElement("script");script.setAttribute("src", "https://yuanshuai1122.github.io/js/algolia.js")
      div.appendChild(script)
      document.body.append(div)
    } else {
      document.body.removeAttribute("style")
      document.body.removeChild(modal)
    }
  }
</script>
    </header>
    
  
  
  <main id="main" class="main">
      <section>
        <article class="article">
          
          <div class=" article-header ">
            <div class="category component">
              <div class="component-content">
                <div class="category-eyebrow">
                  <span class="category-eyebrow__category category_original">
                    
                      
                        Python
                      
                    
                  </span>
                  <span class="category-eyebrow__date">2021年11月26日</span>
                </div>
              </div>
            </div>
            <div class="pagetitle component">
              <div class="component-content">
                <h1 class="hero-headline">Python爬虫之scrapy框架</h1>
              </div>
            </div>
            <div class="component  article-subhead ">
              <div class="component-content"></div>
            </div>

            <div class="tagssheet component">
              <div class="component-content">
                
                  
                  <a href="/tags/python" class="tag">
                    Python
                  </a>
                
                  
                  <a href="/tags/%E7%88%AC%E8%99%AB" class="tag">
                    爬虫
                  </a>
                
              </div>
            </div>
          </div>
          
          <div class="pagebody">
            
            
            
            
            
            
            
            
            
<div class="component-content pagebody component">
  <h2 id="python爬虫之scrapy框架" class="pagebody-header">
    Python爬虫之scrapy框架
  </h2>
</div><div class="component-content component"><ol>
<li>创建项目</li>
</ol></div>
<blockquote>
<p class="component-content component">scrapy startproject 项目名</p>
</blockquote>
<ol start="2">
<li>创建爬虫</li>
</ol></div>
<blockquote>
<p class="component-content component">scrapy  genspider  爬虫识别名称   &lsquo;要爬取的主机地址&rsquo;</p>
</blockquote>
<ol start="3">
<li>运行爬虫</li>
</ol></div>
<blockquote>
<p class="component-content component">scrapy crawl 爬虫识别名称</p>
</blockquote>

<div class="component-content pagebody component">
  <h3 id="1scrapy框架的安装" class="pagebody-header">
    1.Scrapy框架的安装
  </h3>
</div><blockquote>
<p class="component-content component">pip3 install scrapy</p>
</blockquote>

<div class="component-content pagebody component">
  <h3 id="2scrapy框架的简单使用" class="pagebody-header">
    2.Scrapy框架的简单使用
  </h3>
</div><div class="component-content component"><ul>
<li>常用命令</li>
</ul></div>
<blockquote>
<p class="component-content component">创建项目：scrapy startproject xxx
进入项目：cd xxx #进入某个文件夹下
创建爬虫：scrapy genspider xxx（爬虫名） xxx.com （爬取域）
生成文件：scrapy crawl xxx -o xxx.json (生成某种类型的文件)
运行爬虫：scrapy crawl XXX
列出所有爬虫：scrapy list
获得配置信息：scrapy settings [options]</p>
</blockquote>
<div class="component-content component"><ul>
<li>Scrapy项目下包含</li>
</ul></div>
<blockquote>
<p class="component-content component">scrapy.cfg: 项目的配置文件
tutorial/: 该项目的python模块。在此放入代码（核心）
tutorial/items.py: 项目中的item文件.（这是创建容器的地方，爬取的信息分别放到不同容器里）
tutorial/pipelines.py: 项目中的pipelines文件.
tutorial/settings.py: 项目的设置文件.（我用到的设置一下基础参数，比如加个文件头，设置一个编码）
tutorial/spiders/: 放置spider代码的目录. （放爬虫的地方）</p>
</blockquote>
<div class="component-content component"><ul>
<li>
<p class="component-content component">容器（items）的定义，容器不一定是一开始全部都定义好的，可以跟随项目的更新一点点向里面添加</p>
<p class="component-content component">也就是定义我们要爬取的内容</p>
</li>
</ul></div>
<blockquote>
<p class="component-content component">import scrapy
class DmozItem(scrapy.Item): #创建一个类，继承scrapy.item类，就是继承人家写好的容器
title = scrapy.Field() # 需要取哪些内容，就创建哪些容器
link = scrapy.Field()
desc = scrapy.Field()</p>
</blockquote>
<div class="component-content component"><ul>
<li>一个简单爬虫小例子</li>
</ul></div>
<div class="component-content pagebody component code">
  
  
  
  <div class=""><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> scrapy
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DmozSpider</span>(scrapy<span style="color:#f92672">.</span>Spider): <span style="color:#75715e"># 继承Spider类</span>
</span></span><span style="display:flex;"><span>    name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;dmoz&#34;</span> <span style="color:#75715e"># 爬虫的唯一标识，不能重复，启动爬虫的时候要用</span>
</span></span><span style="display:flex;"><span>    allowed_domains <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;dmoz.org&#34;</span>] <span style="color:#75715e"># 限定域名，只爬取该域名下的网页</span>
</span></span><span style="display:flex;"><span>    start_urls <span style="color:#f92672">=</span> [ <span style="color:#75715e"># 开始爬取的链接</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;https://www.baidu.com/&#34;</span>
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">parse</span>(self, response):
</span></span><span style="display:flex;"><span>        filename <span style="color:#f92672">=</span> response<span style="color:#f92672">.</span>url<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;/&#34;</span>)[<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>] <span style="color:#75715e"># 获取url，用”/”分段，获去倒数第二个字段</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(filename, <span style="color:#e6db74">&#39;a&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>            f<span style="color:#f92672">.</span>write(response<span style="color:#f92672">.</span>body) <span style="color:#75715e"># 把访问的得到的网页源码写入文件</span></span></span></code></pre></div></div>
  
</div><p class="component-content component">里面的parse方法，这个方法有两个作用
1.负责解析start_url下载的Response 对象，根据item提取数据（解析item数据的前提是parse里全部requests请求都被加入了爬取队列）
2.如果有新的url则加入爬取队列，负责进一步处理，URL的Request 对象
这两点简单来说就是编写爬虫的主要部分</p>
<p class="component-content component">那么爬虫编写完，我们需要启动爬虫</p>
<blockquote>
<p class="component-content component">cd XXX</p>
</blockquote>
<p class="component-content component">进入到你的文件夹下
输入命令,启动爬虫</p>
<blockquote>
<p class="component-content component">scrapy crawl dmoz</p>
</blockquote>
<p class="component-content component">那么启动爬虫时发生了什么？
Scrapy为Spider的 start_urls 属性中的每个url创建了Request 对象，并将 parse 方法作为回调函数(callback)赋值给了requests,而requests对象经过调度器的调度，执行生成response对象并送回给parse() 方法进行解析,所以请求链接的改变是靠回调函数实现的。</p>
<blockquote>
<p class="component-content component">yield scrapy.Request(self.url, callback=self.parse)</p>
</blockquote>

<div class="component-content pagebody component">
  <h3 id="3scrapy框架的整体架构和组成" class="pagebody-header">
    3.Scrapy框架的整体架构和组成
  </h3>
</div><div class="component-content component"><ul>
<li>官方的Scrapy的架构图</li>
</ul></div>
<p class="component-content component">








<figure class="image component image-fullbleed body-copy-wide nr-scroll-animation nr-scroll-animation--on image-big">  <div class="component-content">
    <div class="image-sharesheet">
      <div class="image image-load image-asset image-8e4a2a3eb1eae98845d8e5a2e32081ef" id="lht8e4a2a3eb1eae98845d8e5a2e32081ef">
        <picture  class="picture">
          <img class="picture-image" data-src="https://hexobbblog.oss-cn-beijing.aliyuncs.com/images/python_spider/1.png" alt=""  />
        </picture>
      </div>
    </div>
    <div class="image-description">
      <div class="image-caption">
        
      </div>
    </div>
  </div>
</figure>
</p>
<blockquote>
<p class="component-content component">图中绿色的是数据的流向
我们看到图里有这么几个东西，分别是
Spiders：爬虫，定义了爬取的逻辑和网页内容的解析规则，主要负责解析响应并生成结果和新的请求
Engine：引擎，处理整个系统的数据流处理，出发事物，框架的核心。
Scheduler：调度器，接受引擎发过来的请求，并将其加入队列中，在引擎再次请求时将请求提供给引擎
Downloader：下载器，下载网页内容，并将下载内容返回给spider
ItemPipeline：项目管道，负责处理spider从网页中抽取的数据，主要是负责清洗，验证和向数据库中存储数据
Downloader Middlewares：下载中间件，是处于Scrapy的Request和Requesponse之间的处理模块
Spider Middlewares：spider中间件，位于引擎和spider之间的框架，主要处理spider输入的响应和输出的结果及新的请求middlewares.py里实现</p>
</blockquote>
<p class="component-content component">








<figure class="image component image-fullbleed body-copy-wide nr-scroll-animation nr-scroll-animation--on image-big">  <div class="component-content">
    <div class="image-sharesheet">
      <div class="image image-load image-asset image-72634626a3804b8db499b979ca104d8e" id="lht72634626a3804b8db499b979ca104d8e">
        <picture  class="picture">
          <img class="picture-image" data-src="https://hexobbblog.oss-cn-beijing.aliyuncs.com/images/python_spider/2.png" alt=""  />
        </picture>
      </div>
    </div>
    <div class="image-description">
      <div class="image-caption">
        
      </div>
    </div>
  </div>
</figure>
</p>
<div class="component-content component"><ul>
<li>最后我们来顺一下scrapy框架的整体执行流程：</li>
</ul></div>
<blockquote>
<p class="component-content component">1.spider的yeild将request发送给engine
2.engine对request不做任何处理发送给scheduler
3.scheduler，生成request交给engine
4.engine拿到request，通过middleware发送给downloader
5.downloader在\获取到response之后，又经过middleware发送给engine
6.engine获取到response之后，返回给spider，spider的parse()方法对获取到的response进行处理，解析出items或者requests
7.将解析出来的items或者requests发送给engine
8.engine获取到items或者requests，将items发送给ItemPipeline，将requests发送给scheduler（ps，只有调度器中不存在request时，程序才停止，及时请求失败scrapy也会重新进行请求）</p>
</blockquote>

<div class="component-content pagebody component">
  <h3 id="4中间件介绍" class="pagebody-header">
    4.中间件介绍
  </h3>
</div><p class="component-content component">请查看xmind思维导图：Scrapy.xmind</p>

<div class="component-content pagebody component">
  <h3 id="5附件" class="pagebody-header">
    5.附件
  </h3>
</div><p class="component-content component">阳光问政平台爬虫（Scrapy实现：2020.7.21） sunSpider项目，详情查看关于我-我的项目</p>

<div class="component-content pagebody component">
  <h2 id="heading" class="pagebody-header">
    
  </h2>
</div>
          </div><div class="component">
            <div class="component-content">
              <div class="article-copyright">
                <p class="content">
                  版权声明: <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed" target="_blank">版权声明：署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0)</a>
                </p>
                <p class="content">作者:  yuanshuai </p>
                <p class="content">发表日期:  2021年11月26日</p>
              </div>
            </div>
          </div></article>
      </section>
  </main>

  <script>
    var script = document.createElement("script");script.src = "https://yuanshuai1122.github.io/js/initPost.js";
    document.head.appendChild(script);
  </script>

    
    <div class="footer-main ">
  <div class="content-body footer-wraper">
    <div class="footer-box">
      <div class="foot-nav">
        <div class="foot-nav-items">
          <div class="item">
            <div class="logo"></div>
            <div class="email">Email: <a href="mailto:shuaiyuan@gmail.com">shuaiyuan@gmail.com</a></div>
          </div>

          <div class="item community">
            <div class="item-title">社交媒体</div>
            
              <a href="https://github.com/yuanshuai1122" target="_blank">Github</a>
            
          </div>

          <div class="item resources">
            <div class="item-title">友链</div>
            
              <a href="https://yuanshuaicn.com/" target="_blank">👋</a>
            
          </div>
        </div>
      </div>
      <div class="bottom">
        <div class="item copyright">
          &copy; 2023
          Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> & <a href="https://github.com/floyd-li/hugo-theme-itheme" target="_blank">iTheme</a>
        </div>
      </div>
    </div>
  </div>
</div>

  </body>
    
    

    
    
</html>
