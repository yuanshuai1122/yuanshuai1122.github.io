<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>爬虫 - 标签 - CN.yuanshuai</title>
    <link>http://yuanshuai1122.github.io/tags/%E7%88%AC%E8%99%AB/</link>
    <description>爬虫 - 标签 - CN.yuanshuai</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sun, 24 Oct 2021 18:38:23 &#43;0000</lastBuildDate><atom:link href="http://yuanshuai1122.github.io/tags/%E7%88%AC%E8%99%AB/" rel="self" type="application/rss+xml" /><item>
  <title>Python爬虫（全）</title>
  <link>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E5%85%A8-python%E7%88%AC%E8%99%AB%E5%85%A8/</link>
  <pubDate>Sun, 24 Oct 2021 18:38:23 &#43;0000</pubDate>
  <author>作者</author>
  <guid>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E5%85%A8-python%E7%88%AC%E8%99%AB%E5%85%A8/</guid>
  <description><![CDATA[（编码encode()） pat=r&quot;(.*?)&quot; data=re.findall(pat,reponse) print(data[0]) ```python #创建自定义opener from urllib import request #构建HTTP处理器对象（专门处理HTTP请求的对象） http_hander=request.HTTPHandler() #创建自定义open]]></description>
</item>
<item>
  <title>Python爬虫之BeautifulSoup</title>
  <link>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Bbeautifulsoup-python%E7%88%AC%E8%99%AB%E4%B9%8Bbeautifulsoup/</link>
  <pubDate>Sun, 24 Oct 2021 18:38:23 &#43;0000</pubDate>
  <author>作者</author>
  <guid>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Bbeautifulsoup-python%E7%88%AC%E8%99%AB%E4%B9%8Bbeautifulsoup/</guid>
  <description><![CDATA[Python爬虫之BeautifulSoup #BeautifulSoup模块简介和安装 from bs4 import BeautifulSoup #CSS 选择器：BeautifulSoup4 #和lx]]></description>
</item>
<item>
  <title>Python爬虫之fiddler手机抓包</title>
  <link>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Bfiddler%E6%89%8B%E6%9C%BA%E6%8A%93%E5%8C%85-python%E7%88%AC%E8%99%AB%E4%B9%8Bfiddler%E6%89%8B%E6%9C%BA%E6%8A%93%E5%8C%85md/</link>
  <pubDate>Sun, 24 Oct 2021 18:38:23 &#43;0000</pubDate>
  <author>作者</author>
  <guid>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Bfiddler%E6%89%8B%E6%9C%BA%E6%8A%93%E5%8C%85-python%E7%88%AC%E8%99%AB%E4%B9%8Bfiddler%E6%89%8B%E6%9C%BA%E6%8A%93%E5%8C%85md/</guid>
  <description><![CDATA[Python爬虫之fiddler手机抓包 fiddler官网：https://www.telerik.com/fiddler 通过Fiddler]]></description>
</item>
<item>
  <title>Python爬虫之requests</title>
  <link>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Brequests-python%E7%88%AC%E8%99%AB%E4%B9%8Brequests/</link>
  <pubDate>Sun, 24 Oct 2021 18:38:23 &#43;0000</pubDate>
  <author>作者</author>
  <guid>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Brequests-python%E7%88%AC%E8%99%AB%E4%B9%8Brequests/</guid>
  <description><![CDATA[Python爬虫之requests 什么是requests？ Requests is an elegant and simple HTTP library for Python, built for human beings. You are currently looking at the documentation of the development release. 通过pip install requests 可以帮你安装它。r]]></description>
</item>
<item>
  <title>Python爬虫之scrapy框架</title>
  <link>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Bscrapy%E6%A1%86%E6%9E%B6-python%E7%88%AC%E8%99%AB%E4%B9%8Bscrapy%E6%A1%86%E6%9E%B6/</link>
  <pubDate>Sun, 24 Oct 2021 18:38:23 &#43;0000</pubDate>
  <author>作者</author>
  <guid>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Bscrapy%E6%A1%86%E6%9E%B6-python%E7%88%AC%E8%99%AB%E4%B9%8Bscrapy%E6%A1%86%E6%9E%B6/</guid>
  <description><![CDATA[Python爬虫之scrapy框架 创建项目 scrapy startproject 项目名 创建爬虫 scrapy genspider 爬虫识别名称 &lsquo;要爬取的主机地址&rsquo; 运行爬虫 scrapy crawl 爬虫识别]]></description>
</item>
<item>
  <title>Python爬虫之urllib</title>
  <link>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Burllib-python%E7%88%AC%E8%99%AB%E4%B9%8Burllib/</link>
  <pubDate>Sun, 24 Oct 2021 18:38:23 &#43;0000</pubDate>
  <author>作者</author>
  <guid>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8Burllib-python%E7%88%AC%E8%99%AB%E4%B9%8Burllib/</guid>
  <description><![CDATA[（编码encode()） pat=r&quot;(.*?)&quot; data=re.findall(pat,reponse) print(data[0]) ```python #创建自定义opener from urllib import request #构建HTTP处理器对象（专门处理HTTP请求的对象） http_hander=request.HTTPHandler() #创建自定义open]]></description>
</item>
<item>
  <title>Python爬虫之多线程</title>
  <link>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B-python%E7%88%AC%E8%99%AB%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/</link>
  <pubDate>Sun, 24 Oct 2021 18:38:23 &#43;0000</pubDate>
  <author>作者</author>
  <guid>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B-python%E7%88%AC%E8%99%AB%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/</guid>
  <description><![CDATA[1&quot;) time.sleep(1) print(&ldquo;线程执行中&mdash;2&rdquo;) time.sleep(1) print(&ldquo;线程执行中&mdash;3&rdquo;]]></description>
</item>
<item>
  <title>Python爬虫之数据写入</title>
  <link>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5-python%E7%88%AC%E8%99%AB%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5/</link>
  <pubDate>Sun, 24 Oct 2021 18:38:23 &#43;0000</pubDate>
  <author>作者</author>
  <guid>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5-python%E7%88%AC%E8%99%AB%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5/</guid>
  <description><![CDATA[Python爬虫之数据写入 #写入到Excel import xlsxwriter #创建文件，并添加一个工作表 workbook=xlsxwriter.Workbook(&#39;demo.xlsx&#39;) worksheet=workbook.add_worksheet() #在指定位置写入数据 worksheet.write(&#34]]></description>
</item>
<item>
  <title>Python爬虫之验证码识别</title>
  <link>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8B%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB-python%E7%88%AC%E8%99%AB%E4%B9%8B%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB/</link>
  <pubDate>Sun, 24 Oct 2021 18:38:23 &#43;0000</pubDate>
  <author>作者</author>
  <guid>http://yuanshuai1122.github.io/posts/python%E7%88%AC%E8%99%AB%E4%B9%8B%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB-python%E7%88%AC%E8%99%AB%E4%B9%8B%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB/</guid>
  <description><![CDATA[Python爬虫之验证码识别 #识别车牌号 from aip import AipOcr import re APP_ID = &#39;15469265&#39; API_KEY = &#39;rAGFtOChXtO7mnRPiwXg1Frf&#39; SECRET_KEY = &#39;Ailvoijh4X7lQIAoZ58UsGPlaDCmLIt7&#39; client = AipOcr(APP_ID, API_KEY, SECRET_KEY) &#34;&#34;&#34; 读取图片 &#34;&#34;&#34; def get_file_content(filePath): with open(filePath, &#39;rb&#39;) as fp: return fp.read() image = get_file_content(r&#39;C:\Users\Administrator\Desktop\img\ee.jpg&#39;) &#34;&#34;&#34; 调用通用文字识别, 图片]]></description>
</item>
<item>
  <title>xpath表达式</title>
  <link>http://yuanshuai1122.github.io/posts/xpath%E8%A1%A8%E8%BE%BE%E5%BC%8F-xpath%E8%A1%A8%E8%BE%BE%E5%BC%8F/</link>
  <pubDate>Tue, 20 Jul 2021 18:38:23 &#43;0000</pubDate>
  <author>作者</author>
  <guid>http://yuanshuai1122.github.io/posts/xpath%E8%A1%A8%E8%BE%BE%E5%BC%8F-xpath%E8%A1%A8%E8%BE%BE%E5%BC%8F/</guid>
  <description><![CDATA[Python爬虫之xpath表达式 #xpath表达式 #有同学说，我正则用的不好，处理HTML文档很累，有没有其他的方法？ #有！那就是XPat]]></description>
</item>
</channel>
</rss>
